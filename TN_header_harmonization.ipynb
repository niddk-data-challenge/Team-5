{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0da9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5964147 entries, 0 to 5964154\n",
      "Columns: 889 entries, MaskID to howmanydoseshastheparticipantm\n",
      "dtypes: Int64(233), category(470), float16(182), float64(3), int64(1)\n",
      "memory usage: 16.7 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_feather('all_merged_99.feather')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680efda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                                                       Size  Used Avail Use% Mounted on\r\n",
      "devtmpfs                                                          35G     0   35G   0% /dev\r\n",
      "tmpfs                                                             35G     0   35G   0% /dev/shm\r\n",
      "tmpfs                                                             35G  816K   35G   1% /run\r\n",
      "tmpfs                                                             35G     0   35G   0% /sys/fs/cgroup\r\n",
      "/dev/nvme0n1p1                                                   135G   87G   49G  64% /\r\n",
      "/dev/nvme1n1                                                      20G   15G  4.1G  79% /home/ec2-user/SageMaker\r\n",
      "tmpfs                                                            6.9G     0  6.9G   0% /run/user/1002\r\n",
      "tmpfs                                                            6.9G     0  6.9G   0% /run/user/1001\r\n",
      "tmpfs                                                            6.9G     0  6.9G   0% /run/user/0\r\n",
      "tmpfs                                                            6.9G     0  6.9G   0% /run/user/1000\r\n",
      "459029135025-prod-va-sw-p-studydata:studies/Organization/TN_01/  1.0P     0  1.0P   0% /home/ec2-user/studies/TN_01\r\n",
      "459029135025-prod-va-sw-p-studydata:studies/Organization/TN_19/  1.0P     0  1.0P   0% /home/ec2-user/studies/TN_19\r\n",
      "459029135025-prod-va-sw-p-studydata:studies/Organization/TN_20/  1.0P     0  1.0P   0% /home/ec2-user/studies/TN_20\r\n",
      "459029135025-prod-va-sw-p-studydata:studies/Organization/TN_16/  1.0P     0  1.0P   0% /home/ec2-user/studies/TN_16\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32e244",
   "metadata": {},
   "source": [
    "# 1. Columns of Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737a423",
   "metadata": {},
   "source": [
    "#### Steps of date column harmonization:\n",
    "1. Filter out date column sets based on their headers\n",
    "2. Create one date column to replace one set of date columns.\n",
    "3. assign values in the format of date_time to the new created column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef81021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cff8512",
   "metadata": {},
   "source": [
    "## 1.1 Day, Month, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ef598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  102 columns:  ['_15Aug2011ConsentDateDay', '_15Aug2011ConsentDateMonth', '_15Aug2011ConsentDateYear', 'Fall2017ConsentDateDay', 'Fall2017ConsentDateMonth', 'Fall2017ConsentDateYear', 'DateOfBloodDrawDay', 'DateOfBloodDrawMonth', 'DateOfBloodDrawYear', 'DateReportedDay', 'DateReportedMonth', 'DateReportedYear', 'ScreeningDay', 'ScreeningMonth', 'ScreeningYear', 'ConsentSignedDay', 'ConsentSignedMonth', 'ConsentSignedYear', 'Spring2019ConsentDateMonth_dup12', 'Spring2019ConsentDateDay_dup12', 'Spring2019ConsentDateYear_dup12', 'DateConsentSignedDay', 'DateConsentSignedMonth', 'DateConsentSignedYear', 'SamplesCollectionDay', 'SamplesCollectionMonth', 'SamplesCollectionYear', 'SamplesCollectionDay_dup15', 'SamplesCollectionMonth_dup15', 'SamplesCollectionYear_dup15', 'DateConsentSignedDay_dup15', 'DateConsentSignedMonth_dup15', 'DateConsentSignedYear_dup15', 'DateStatusChangeDay', 'DateStatusChangeMonth', 'DateStatusChangeYear', 'ProtcolDeviationDay', 'ProtcolDeviationMonth', 'ProtcolDeviationYear', 'AEReportDtDay', 'AEReportDtMonth', 'AEReportDtYear', 'AEOccurDtDay', 'AEOccurDtMonth', 'AEOccurDtYear', 'AEResolveDtDay', 'AEResolveDtMonth', 'AEResolveDtYear', 'DoWDay', 'DoWMonth', 'DoWYear', 'DoRDay', 'DoRMonth', 'DoRYear', 'AssessDateDay', 'AssessDateMonth', 'AssessDateYear', 'StartDateDay', 'StartDateMonth', 'StartDateYear', 'StopDateDay', 'StopDateMonth', 'StopDateYear', 'LastHbA1cDay', 'LastHbA1cMonth', 'LastHbA1cYear', 'InformedConsentDay', 'InformedConsentMonth', 'InformedConsentYear', 'DateProtocolDeviationDay', 'DateProtocolDeviationMonth', 'DateProtocolDeviationYear', 'DateTestsRunMonth', 'DateTestsRunDay', 'DateTestsRunYear', 'DiagnosisDay', 'DiagnosisMonth', 'DiagnosisYear', 'InsulinTreatmentStartedDay', 'InsulinTreatmentStartedMonth', 'InsulinTreatmentStartedYear', 'GlucoseDay1_1', 'GlucoseMonth1_1', 'GlucoseYear1_1', 'GlucoseDay2_1', 'GlucoseMonth2_1', 'GlucoseYear2_1', 'GlucoseDay3_1', 'GlucoseMonth3_1', 'GlucoseYear3_1', 'HbA1cDay', 'HbA1cMonth', 'HbA1cYear', 'StudyDrugReturnedDay', 'StudyDrugReturnedMonth', 'StudyDrugReturnedYear', 'StudyDrugDispensedDay', 'StudyDrugDispensedMonth', 'StudyDrugDispensedYear', 'ContactDateDay', 'ContactDateMonth', 'ContactDateYear']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5964147 entries, 0 to 5964154\n",
      "Columns: 102 entries, _15Aug2011ConsentDateDay to ContactDateYear\n",
      "dtypes: Int64(71), category(31)\n",
      "memory usage: 3.8 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Filter all columns with \"Day\", \"Month\", \"Year\" as date sets\n",
    "# in lower case for case-insensitive comparison\n",
    "# Example strings to include\n",
    "contain_list_1 = ['Day', \"Month\", 'Year'] \n",
    "# Example strings to exclude\n",
    "not_contain_list_1 = ['LastYear', 'Last6Months', '3Days', 'Birth', 'MostRecentHbA1c', 'PastYear', \n",
    "                      'ChangeInDrugStatusEffective', 'ParticipantDateDispensed', 'MechanisticSampleCollection',\n",
    "                     'Polydipsia', 'Polyuria']     \n",
    "\n",
    "# Converting each string in the lists to lower case\n",
    "contain_list_1_low = [string.lower() for string in contain_list_1]\n",
    "not_contain_list_1_low = [string.lower() for string in not_contain_list_1]\n",
    "\n",
    "# Filtering columns with case-insensitive comparison\n",
    "filtered_date_columns_1 = [col for col in df.columns if \n",
    "                    any(contain in col.lower() for contain in contain_list_1_low) and \n",
    "                    all(not_contain not in col.lower() for not_contain in not_contain_list_1_low)]\n",
    "\n",
    "print(\"Found \", len(filtered_date_columns_1), \"columns: \", filtered_date_columns_1)\n",
    "\n",
    "filtered_df = df[filtered_date_columns_1]\n",
    "\n",
    "# Output the filtered DataFrame\n",
    "print(filtered_df.info())\n",
    "\n",
    "# Uncomment if you want to print top 20 values for each column\n",
    "#for col in filtered_columns:\n",
    "#    print(f\"Top 20 values for column {col}:\")\n",
    "#    print(df[col].value_counts().nlargest(20))\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac360c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of the day columes to be merged:  34\n",
      "No. of month columes in wrong naming format:  0\n",
      "No. of year columes in wrong naming format:  0\n"
     ]
    }
   ],
   "source": [
    "#check columns for the day\n",
    "day_column_list_1 = [col for col in filtered_date_columns_1 if \"Day\" in col]\n",
    "print(\"No. of the day columes to be merged: \", len(day_column_list_1))\n",
    "\n",
    "#create columns for the month and the year based on columns of the day\n",
    "month_column_list_1 = [name.replace(\"Day\", \"Month\") for name in day_column_list_1]\n",
    "year_column_list_1 = [name.replace(\"Day\", \"Year\") for name in day_column_list_1]\n",
    "\n",
    "#check whether there are any columns in the dataframe not following the naming rules\n",
    "unmatched_month_columns = [name for name in month_column_list_1 if name not in df.columns]\n",
    "print(\"No. of month columes in wrong naming format: \", len(unmatched_month_columns))\n",
    "\n",
    "unmatched_year_columns = [name for name in year_column_list_1 if name not in df.columns]\n",
    "print(\"No. of year columes in wrong naming format: \", len(unmatched_year_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9493f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert 'NA' strings to np.nan\n",
    "def convert_na(value):\n",
    "    if pd.isna(value):  # using pandas function to check for NA\n",
    "        return np.nan   # converting to numpy NaN\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Function to convert month from string or number to numeric month, handling missing values\n",
    "def month_to_num(month):\n",
    "    if pd.isna(month):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Handle string representation\n",
    "        if isinstance(month, str):\n",
    "            datetime_object = pd.to_datetime(month, format='%b')\n",
    "            return datetime_object.month\n",
    "        # Handle numeric representation\n",
    "        elif isinstance(month, (int, float)):\n",
    "            return int(month)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "# Create a date column and assign values by combine date columns with similar header\n",
    "def create_date_column(df, year_col, original_cols):\n",
    "    parts = year_col.split('Year')\n",
    "    base_col_name = parts[0]\n",
    "    suffix = parts[1] if len(parts) > 1 else ''\n",
    "\n",
    "    day_col = base_col_name + 'Day' + suffix\n",
    "    month_col = base_col_name + 'Month' + suffix\n",
    "\n",
    "    if day_col in original_cols and month_col in original_cols:\n",
    "        date_col = base_col_name + 'Date' + suffix\n",
    "        problematic_rows = []\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                if pd.isna(row[year_col]) or pd.isna(row[month_col]) or pd.isna(row[day_col]):\n",
    "                    df.at[index, date_col] = np.nan\n",
    "                else:\n",
    "                    year = int(row[year_col])\n",
    "                    month = int(month_to_num(row[month_col]))\n",
    "                    day = int(row[day_col])\n",
    "                    datetime_obj = pd.to_datetime(f\"{year}-{month:02d}-{day:02d}\", errors='coerce')\n",
    "                    df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n",
    "            except (ValueError, OverflowError) as e:\n",
    "                problematic_rows.append((index, row[year_col], row[month_col], row[day_col]))\n",
    "                df.at[index, date_col] = np.nan\n",
    "        if problematic_rows:\n",
    "            print(\"Problematic rows:\")\n",
    "            for row in problematic_rows:\n",
    "                print(row)\n",
    "    else:\n",
    "        print(f\"Matching columns for '{year_col}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15472c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9130/375426993.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n",
      "/tmp/ipykernel_9130/375426993.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2015-07-01' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n",
      "/tmp/ipykernel_9130/375426993.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, date_col] = np.nan\n",
      "/tmp/ipykernel_9130/375426993.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2018-01-24' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n",
      "/tmp/ipykernel_9130/375426993.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, date_col] = np.nan\n",
      "/tmp/ipykernel_9130/375426993.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2017-12-14' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n",
      "/tmp/ipykernel_9130/375426993.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[index, date_col] = np.nan\n",
      "/tmp/ipykernel_9130/375426993.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2017-12-14' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, date_col] = datetime_obj.date()  # Extracting just the date part\n"
     ]
    }
   ],
   "source": [
    "# Convert 'NA' strings to np.nan\n",
    "for col in filtered_date_columns_1:\n",
    "    filtered_df.loc[:, col] = filtered_df[col].apply(convert_na)\n",
    "\n",
    "# Iterating over columns and creating date columns\n",
    "for col in year_column_list_1:\n",
    "    create_date_column(filtered_df, col, filtered_date_columns_1)\n",
    "\n",
    "print(filtered_df.info())\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e136b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def18ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85631336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e359e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da712380",
   "metadata": {},
   "source": [
    "## 1.2 Month, Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03b6ac",
   "metadata": {},
   "source": [
    "'BirthMonth', 'BirthYear'\n",
    "'MostRecentHbA1cMonth', 'MostRecentHbA1cYear'\n",
    "'PolyuriaMonth', 'PolyuriaYear'\n",
    "'PolydipsiaMonth', 'Polydipsiayear', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b2858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db1dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea1413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d65cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c21120f7",
   "metadata": {},
   "source": [
    "## 1.3 DD, MM, YYYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d51f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28dc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde9d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f3663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b88f0b",
   "metadata": {},
   "source": [
    "## 1.4 day, mon, yea"
   ]
  },
  {
   "cell_type": "raw",
   "id": "689c8a02",
   "metadata": {},
   "source": [
    "ChangeInDrugStatusEffective\n",
    "ParticipantDateDispensed\n",
    "'MechanisticSampleCollectionDay', 'MechanisticSampleCollectionMon', 'MechanisticSampleCollectionYea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af611f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
